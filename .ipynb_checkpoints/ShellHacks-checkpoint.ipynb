{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Content Moderator Azure Cognitive Services \n",
    "\n",
    "First create a service in [Azure Portal](https://portal.azure.com)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade azure-cognitiveservices-vision-contentmoderator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azure.cognitiveservices.vision.contentmoderator import ContentModeratorClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "key=\"4a1121e7374c457990057dfb7fafe689\"\n",
    "endpoint= \"https://shellhacks-twitter.cognitiveservices.azure.com/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client = ContentModeratorClient(endpoint, CognitiveServicesCredentials(key))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./db.txt\",\"rb\") as text_file:\n",
    "    text_moderation = client.text_moderation.screen_text(\n",
    "        text_content_type=\"text/plain\",\n",
    "        text_content=text_file,\n",
    "        language=\"eng\",\n",
    "        autocorrect=True,\n",
    "        pii=True\n",
    "    )\n",
    "pprint(text_moderation.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "term_list = client.list_management_term_lists.create(\n",
    "    content_type=\"application/json\",\n",
    "    body={\n",
    "        \"name\":\"Custom list\", \n",
    "        \"description\":\"Custom term description\"\n",
    "    }\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "client.list_management_term.add_term(\n",
    "    list_id=term_list.id,\n",
    "    term= \"shenanigans\",\n",
    "    language=\"eng\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_term = client.list_management_term.get_all_terms(list_id=term_list.id, language=\"eng\")\n",
    "\n",
    "pprint(custom_term.as_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"./data2.txt\", \"rb\") as custom_text:\n",
    "    screen_text = client.text_moderation.screen_text(\n",
    "        text_content_type=\"text/plain\",\n",
    "        text_content=custom_text,\n",
    "        language=\"eng\",\n",
    "        autocorrect=True,\n",
    "        pii=True,\n",
    "        list_id=term_list.id\n",
    "    )\n",
    "    \n",
    "pprint(screen_text.as_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Trying to use a twitter json fragment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"./data.json\", \"r\")\n",
    "content = file.read()\n",
    "\n",
    "decode = json.dumps(content)\n",
    "data = ast.literal_eval(decode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "data = [json.loads(line) for line in open('./data.json', 'r')]\n",
    "\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data\n",
    "\n",
    "First, access to the twitter dataset from [HERE](https://archive.org/download/archiveteam-twitter-stream-2019-05)\n",
    "\n",
    "Then download twitter_stream_2019_05_02.tar file and we open 29.json, this is the file that we used to work for this event.\n",
    "\n",
    "We have to many language options available, but we'll working with \"en\" language to can moderate \n",
    "So we have to filter all english tweets, and rt's\n",
    "\n",
    "\n",
    "### Json to CSV\n",
    "\n",
    "We'll use pandas to convert a Json to CSV, apply filter and get a new json with all english content.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_json = pd.read_json(\"./29.json\",lines=True)\n",
    "df_json.to_csv(\"29.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv \n",
    "import json \n",
    "\n",
    "\n",
    "# Function to convert a CSV to JSON \n",
    "# Takes the file paths as arguments \n",
    "def make_json(csvFilePath, jsonFilePath): \n",
    "    # create a dictionary\n",
    "    data = {}\n",
    "    # Open a csv reader called DictReader \n",
    "    with open(csvFilePath, encoding='utf-8') as csvf: \n",
    "        csvReader = csv.DictReader(csvf)\n",
    "        # Convert each row into a dictionary \n",
    "        # and add it to data \n",
    "        for rows in csvReader: \n",
    "            # Assuming a column named 'No' to \n",
    "            # be the primary key \n",
    "            key = rows['id'] \n",
    "            data[key] = rows \n",
    "            \n",
    "        # Open a json writer, and use the json.dumps() \n",
    "        # function to dump data \n",
    "        with open(jsonFilePath, 'w', encoding='utf-8') as jsonf: \n",
    "            jsonf.write(json.dumps(data, indent=4))\n",
    "            \n",
    "# Driver Code \n",
    "\n",
    "# Decide the two file paths according to your \n",
    "# computer system \n",
    "csvFilePath = r'./db.csv'\n",
    "jsonFilePath = r'./db.json'\n",
    "\n",
    "# Call the make_json function \n",
    "make_json(csvFilePath, jsonFilePath)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Json as Dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('./029.json','r') as j:\n",
    "    json_text = j.read()\n",
    "    \n",
    "#Decode the JSON string into a pythin dictionary\n",
    "apod_dict = json.loads(json_text)\n",
    "print(apod_dict['1'])\n",
    "\n",
    "# Encode the python dict into a JSON String\n",
    "new_json_string = json.dumps(apod_dict, indent=4)\n",
    "new_json_string.replace(\"\\\", \"\")\n",
    "print(new_json_string)\n",
    "\n",
    "n = open('db.txt','w')\n",
    "n.write(str(new_json_string))\n",
    "n.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
